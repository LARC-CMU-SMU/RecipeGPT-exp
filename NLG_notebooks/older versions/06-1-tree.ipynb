{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!pip install zss==1.2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 5.01 µs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "%load_ext autotime\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "# if cannot import the modules, add the parent directory to system path might help\n",
    "\n",
    "import os, tqdm, sys\n",
    "parent_dir = os.path.abspath(os.getcwd()+'/..')+'/'\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "from utils.path import dir_HugeFiles\n",
    "from utils.preprocessing import load\n",
    "from utils.save import make_dir, save_pickle, load_pickle, save\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import copy\n",
    "import re\n",
    "import tqdm\n",
    "import zss\n",
    "\n",
    "'''useful for displaying dictionary\n",
    "import pprint\n",
    "pprint.pprint(recipe_inst)\n",
    "'''\n",
    "from gensim.models import KeyedVectors\n",
    "gensim_model = KeyedVectors.load_word2vec_format('../data/vocab.bin', binary = True)\n",
    "vocabulary = gensim_model.vocab.keys()\n",
    "# gensim_model.get_vector('cook')\n",
    "from ete3 import Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/timtadh/zhang-shasha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a basic tree and display the similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---tree edit distance:---\n",
      "1.0\n",
      "\n",
      "---examples of accessing the nodes---\n",
      "A1\n",
      "I\n",
      "time: 26 ms\n"
     ]
    }
   ],
   "source": [
    "def scoring_function(a, b):\n",
    "    if a == b:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "class Node(object):\n",
    "    def __init__(self, label, nodetype):\n",
    "        # assert type(label) == str\n",
    "        self.label = label\n",
    "        self.children = list()\n",
    "        self.nodetype = nodetype\n",
    "\n",
    "    @staticmethod\n",
    "    def get_children(node):\n",
    "        return node.children\n",
    "\n",
    "    @staticmethod\n",
    "    def get_label(node):\n",
    "        return node.label\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_nodetype(node):\n",
    "        return node.nodetype\n",
    "    \n",
    "    def addkid(self, node, before=False):\n",
    "        if before:  self.children.insert(0, node)\n",
    "        else:   self.children.append(node)\n",
    "        return self\n",
    "    \n",
    "A = (Node(\"A1\",\"action\").addkid(Node(\"I\", \"ingredient\")))\n",
    "B = (Node(\"A2\",\"action\").addkid(Node(\"I\", \"ingredient\")))\n",
    "\n",
    "dist = zss.simple_distance(A, B, Node.get_children, Node.get_label, scoring_function)\n",
    "print('---tree edit distance:---')\n",
    "print(dist)\n",
    "print()\n",
    "print('---examples of accessing the nodes---')\n",
    "print(Node.get_label(A))\n",
    "first_children_of_A = Node.get_children(A)[0]\n",
    "print(Node.get_label(first_children_of_A))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build recipe tree and display the similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 59.1 ms\n"
     ]
    }
   ],
   "source": [
    "def make_nodes(sentence):\n",
    "    action = Node(label=sentence['word'], nodetype='action')\n",
    "    for ing in sentence['ingredient']:\n",
    "        action.addkid(Node(label=ing, nodetype='ingredient'))\n",
    "    return action\n",
    "\n",
    "def build_tree(recipe_inst):\n",
    "    '''\n",
    "    recipe_inst = [{'word': 'verb1', 'ingredient':['A1','B1','C1','D1']},\n",
    "                   {'word': 'verb2', 'ingredient':['A2','B2','C2','D2']},\n",
    "                   {'word': 'verb3', 'ingredient':['A3','B3','C3','D3']}\n",
    "                  ]\n",
    "    '''\n",
    "    tree1 = Node(label=recipe_inst[0]['word'], nodetype='action')\n",
    "    for ing in recipe_inst[0]['ingredient']:\n",
    "        tree1.addkid(Node(label=ing, nodetype='ingredient')\n",
    "                    )\n",
    "    myroot = tree1\n",
    "    recipe_inst = recipe_inst[1:]\n",
    "    for sentence in recipe_inst:\n",
    "        myroot.addkid(make_nodes(sentence), before=True)\n",
    "        myroot = Node.get_children(myroot)[0]\n",
    "    return tree1\n",
    "\n",
    "'''compare the number of edit'''\n",
    "def strdist(a, b): return 0 if a == b else 1\n",
    "\n",
    "def cosine_distance(vector_a, vector_b):\n",
    "        cosine_similarity =  np.dot(vector_a, vector_b)/(np.linalg.norm(vector_a)* np.linalg.norm(vector_b))\n",
    "        return 1 - cosine_similarity\n",
    "    \n",
    "'''compare the cosine distance of node'''\n",
    "def wordvec_dist(a, b):\n",
    "    assert a in vocabulary\n",
    "    assert b in vocabulary\n",
    "    if a == b: \n",
    "        return 0\n",
    "    else:\n",
    "        vector_a, vector_b = gensim_model.get_vector(a), gensim_model.get_vector(b)\n",
    "        return cosine_distance(vector_a, vector_b)\n",
    "    \n",
    "def tree_distance(tree1, tree2):\n",
    "    return zss.distance(tree1, tree2, \n",
    "             Node.get_children,\n",
    "             insert_cost=lambda node: strdist('', Node.get_label(node)),\n",
    "             remove_cost=lambda node: strdist(Node.get_label(node), ''),\n",
    "             update_cost=lambda a, b: wordvec_dist(Node.get_label(a), Node.get_label(b))\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Draw the tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "         /-rice\n",
      "        |\n",
      "        |--banana\n",
      "        |\n",
      "        |--cookie\n",
      "        |\n",
      "-- /heated-dishes\n",
      "        |\n",
      "        |    /-apple\n",
      "        |   |\n",
      "        |   |--banana\n",
      "        |   |\n",
      "        |   |--cookie\n",
      "         \\boil\n",
      "            |--dish\n",
      "            |\n",
      "            |     /-apple\n",
      "            |    |\n",
      "            |    |--banana\n",
      "             \\rince\n",
      "                 |--cookie\n",
      "                 |\n",
      "                  \\-dish\n",
      "time: 25.1 ms\n"
     ]
    }
   ],
   "source": [
    "def draw_tree(recipe_inst):\n",
    "    '''\n",
    "    from ete3 import Tree\n",
    "    recipe_inst = [{'word': 'heated', 'ingredient':['rice','banana','cookie','dishes']},\n",
    "                   {'word': 'boil', 'ingredient':['apple','banana','cookie','dish']},\n",
    "                   {'word': 'rince', 'ingredient':['apple','banana','cookie','dish']}\n",
    "                  ]\n",
    "    '''\n",
    "    # sorting will not improve the tree edit distance\n",
    "    # if sort:\n",
    "    #    recipe_inst = [{'word':line['word'], 'ingredient': sorted(line['ingredient'])} for line in recipe_inst]\n",
    "        \n",
    "    output = Tree()\n",
    "    temp = output\n",
    "    for i in recipe_inst:\n",
    "        t = Tree(name=i['word'])\n",
    "        t.add_feature('type', 'action')\n",
    "        if not i['ingredient']:\n",
    "            pass\n",
    "        else:\n",
    "            for j in i['ingredient']:\n",
    "                a = t.get_tree_root().add_child(name=j)\n",
    "                a.add_feature('type', 'ingredient')\n",
    "            temp = temp.add_child(t)\n",
    "    print(output.get_ascii(show_internal=True))\n",
    "    return output\n",
    "recipe_inst = [{'word': 'heated', 'ingredient':['rice','banana','cookie','dishes']},\n",
    "               {'word': 'boil', 'ingredient':['apple','banana','cookie','dish']},\n",
    "               {'word': 'rince', 'ingredient':['apple','banana','cookie','dish']}\n",
    "              ]\n",
    "example_tree = draw_tree(recipe_inst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "         /-rice\n",
      "        |\n",
      "-- /heated-banana\n",
      "        |\n",
      "        |    /-cookie\n",
      "         \\boil\n",
      "             \\-dish\n",
      "\n",
      "         /-banana\n",
      "        |\n",
      "-- /heated-rice\n",
      "        |\n",
      "         \\boiled-cookie\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.8127352595329285"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 57.3 ms\n"
     ]
    }
   ],
   "source": [
    "recipe_inst = [{'word': 'heated', 'ingredient':['rice','banana']},\n",
    "               {'word': 'boil', 'ingredient':['cookie','dish']},\n",
    "              ]\n",
    "tree1 = build_tree(recipe_inst)\n",
    "example_tree1 = draw_tree(recipe_inst)\n",
    "recipe_inst = [{'word': 'heated', 'ingredient':['banana','rice']},\n",
    "               {'word': 'boiled', 'ingredient':['cookie']},\n",
    "              ]\n",
    "tree2 = build_tree(recipe_inst)\n",
    "example_tree2 = draw_tree(recipe_inst)\n",
    "tree_distance(tree1, tree2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "         /-rice\n",
      "        |\n",
      "-- /heated-banana\n",
      "        |\n",
      "        |    /-cookie\n",
      "         \\boil\n",
      "             \\-dish\n",
      "\n",
      "         /-banana\n",
      "        |\n",
      "-- /heated-rice\n",
      "        |\n",
      "         \\boil-cookie\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 55.7 ms\n"
     ]
    }
   ],
   "source": [
    "recipe_inst = [{'word': 'heated', 'ingredient':['rice','banana']},\n",
    "               {'word': 'boil', 'ingredient':['cookie','dish']},\n",
    "              ]\n",
    "tree1 = build_tree(recipe_inst)\n",
    "example_tree1 = draw_tree(recipe_inst)\n",
    "recipe_inst = [{'word': 'heated', 'ingredient':['banana','rice']},\n",
    "               {'word': 'boil', 'ingredient':['cookie']},\n",
    "              ]\n",
    "tree2 = build_tree(recipe_inst)\n",
    "example_tree2 = draw_tree(recipe_inst)\n",
    "tree_distance(tree1, tree2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0272054951637983"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 46.6 ms\n"
     ]
    }
   ],
   "source": [
    "wordvec_dist('rice', 'banana')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conduct on real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exist ../big_data/dic_20190927.pickle\n",
      "time: 4.26 s\n"
     ]
    }
   ],
   "source": [
    "dic = load(dir_save = '../big_data/dic_20190927.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load ../../to_gpt2/generation_28k_sorted/\n",
      "time: 226 ms\n"
     ]
    }
   ],
   "source": [
    "### STEP2 load and clean the generation\n",
    "\n",
    "def reverse(text):\n",
    "    '''\n",
    "    Important data cleaning before NY times parser\n",
    "    '''\n",
    "    # replace things in brace\n",
    "    text = re.sub(r'\\([^)]*\\)', '', text)\n",
    "\n",
    "    # remove space before punct\n",
    "    text = re.sub(r'\\s([?.!,\"](?:\\s|$))', r'\\1', text)\n",
    "\n",
    "    # remove consecutive spaces\n",
    "    text = re.sub(' +',' ',text).strip()\n",
    "    return text\n",
    "\n",
    "def reverse_list(listoftext):\n",
    "    output=[]\n",
    "    for text in listoftext:\n",
    "        rev = reverse(text)\n",
    "        if rev:\n",
    "            output.append(rev)\n",
    "    return output\n",
    "\n",
    "def load_dir_data(filename):\n",
    "    ls = []\n",
    "    if os.path.isdir(filename):\n",
    "        print('load', filename)\n",
    "        # Directory\n",
    "        for (dirpath, _, fnames) in os.walk(filename):\n",
    "            for fname in fnames:\n",
    "                path = os.path.join(dirpath, fname)\n",
    "                with open(path, 'r') as fp:\n",
    "                    raw_text = fp.read()\n",
    "                    \n",
    "                # if it contains instr\n",
    "                if fname[-5] == 'd':\n",
    "                    dic[int(fname[:-5])]['generated_instr'] = reverse_list(raw_text.split('.'))\n",
    "                    # ls.append(int(fname[:-5])) # only interested in instr\n",
    "                # if it contains ingred\n",
    "                if fname[-5] == 'i':\n",
    "                    dic[int(fname[:-5])]['generated_ingred'] = reverse_list(raw_text.split('$'))\n",
    "                    \n",
    "                # if it contains name\n",
    "                if fname[-5] == 't':\n",
    "                    dic[int(fname[:-5])]['generated_name'] = raw_text\n",
    "                    \n",
    "                ls.append(int(fname[:-5])) # three fields\n",
    "                \n",
    "                    \n",
    "    return sorted(list(set(ls)))\n",
    "\n",
    "filename = '../../to_gpt2/generation_28k_sorted/'\n",
    "ls = load_dir_data(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 27.5 ms\n"
     ]
    }
   ],
   "source": [
    "class instr2tree:\n",
    "    def __init__(self):\n",
    "        self.spacy = spacy.load('en_core_web_lg')\n",
    "        self.vocabulary= list(vocabulary)\n",
    "        \n",
    "    def sents2tree(self, sents):\n",
    "        '''\n",
    "        contatenate the leaves to a big tree\n",
    "        '''\n",
    "        tree = []\n",
    "        for sent in sents:\n",
    "            temp = self.leaf(sent)\n",
    "            if temp:\n",
    "                for t in temp:\n",
    "                    if t['word']:\n",
    "                        tree.append(t)\n",
    "                    else:\n",
    "                        ''' while creating the leaf, I force every leaf to have a content in \"word\"\n",
    "                            so that I can avoid the IndexError in tree[-1] '''\n",
    "                        tree[-1]['ingredient'] += t['ingredient']\n",
    "        return tree\n",
    "    \n",
    "    def leaf(self, sent):\n",
    "        '''\n",
    "        transform a sentence to a leaf\n",
    "        '''\n",
    "        doc = self.spacy(sent)\n",
    "        verbs = [(token.i, token.lemma_) for token in doc \\\n",
    "                 if token.pos_ == 'VERB' and token.lemma_ in self.vocabulary]\n",
    "        nouns = [(chunk.root.i, chunk.root.lemma_) for chunk in doc.noun_chunks \\\n",
    "                 if chunk.root.lemma_ not in ['-PRON-'] and chunk.root.lemma_ in self.vocabulary]\n",
    "        \n",
    "        if not verbs and not nouns:\n",
    "            return \n",
    "        \n",
    "        # if do not have a noun, just add the verb\n",
    "        elif not nouns: \n",
    "            return [{'word': v, 'ingredient': []} for vidx, v in verbs]\n",
    "        \n",
    "        # if do not have a verb, automatically set the first word in noun to verb\n",
    "        elif not verbs: \n",
    "            return [{'word': nouns[0][1], 'ingredient': [n for nidx, n in nouns[1:]]}]\n",
    "        \n",
    "        '''\n",
    "        verbs=[(0, 'v1'),(1,'v2'),(6, 'v3'),(8,'v4'),(10,'v5')]\n",
    "        nouns=[(2, 'n1'),(3,'n2'),(4, 'n3'),(7,'n4'), (9,'n5'),(12,'n6')]\n",
    "        1) loop through verb\n",
    "        2) check verb whether > noun\n",
    "        3) if > then next noun\n",
    "        4) if not then next verb\n",
    "        '''\n",
    "        output, sent, vidx, nidx = [], [], 1, 0\n",
    "        while vidx < len(verbs):\n",
    "            if nidx < len(nouns) and nouns[nidx] < verbs[vidx]:\n",
    "                sent.append(nouns[nidx][1])\n",
    "                nidx += 1\n",
    "            else:\n",
    "                output.append({'word':verbs[vidx-1][1], 'ingredient': sent})\n",
    "                vidx +=1\n",
    "                sent = []\n",
    "        while nidx < len(nouns):\n",
    "            sent.append(nouns[nidx][1])\n",
    "            nidx += 1\n",
    "        output.append({'word':verbs[vidx-1][1], 'ingredient': sent})\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'word': 'stir', 'ingredient': ['ketchup', 'mustard', 'plate']},\n",
       " {'word': 'mix', 'ingredient': []},\n",
       " {'word': 'stir', 'ingredient': ['ketchup', 'mustard', 'plate']},\n",
       " {'word': 'mix', 'ingredient': []}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 10.2 s\n"
     ]
    }
   ],
   "source": [
    "treemaker = instr2tree()\n",
    "treemaker.sents2tree(['stir together ketchup and mustard on a plate and mix them.',\n",
    "                     'stir together ketchup and mustard on a plate and mix them.'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [02:48<00:00,  3.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2min 48s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm.tqdm(ls): \n",
    "    dic[i]['tree_true'],dic[i]['tree_pred'] = [],[]\n",
    "    dic[i]['tree_true'] = treemaker.sents2tree(dic[i]['directions'])\n",
    "    dic[i]['tree_pred'] = treemaker.sents2tree(dic[i]['generated_instr'])\n",
    "    tree1 = build_tree(dic[i]['tree_true'])\n",
    "    tree2 = build_tree(dic[i]['tree_pred'])\n",
    "    dic[i]['#tree_dist'] = tree_distance(tree1, tree2)\n",
    "    len_true = sum([len(sent['ingredient']) + 1 for sent in dic[i]['tree_true']])\n",
    "    len_pred = sum([len(sent['ingredient']) + 1 for sent in dic[i]['tree_pred']])\n",
    "    BP = len_pred/len_true\n",
    "    dic[i]['#BP'] = BP if BP < 1 else 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "#tree_dist    42.738515\n",
       "#BP            0.817516\n",
       "dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.36 s\n"
     ]
    }
   ],
   "source": [
    "### 28k full\n",
    "df2 = pd.DataFrame.from_dict(dic, orient = 'index')\n",
    "temp = df2[[col for col in df2.columns if '#' in col]].iloc[ls].mean()\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 26.5 ms\n"
     ]
    }
   ],
   "source": [
    "#(df2.iloc[ls]['#tree_dist']/df2.iloc[ls]['#BP']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load ../../to_gpt2/generation_333k_sorted/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [02:42<00:00,  3.09it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "#tree_dist    41.158559\n",
       "#BP            0.800247\n",
       "dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2min 45s\n"
     ]
    }
   ],
   "source": [
    "filename = '../../to_gpt2/generation_333k_sorted/'\n",
    "ls = load_dir_data(filename)\n",
    "for i in tqdm.tqdm(ls): \n",
    "    dic[i]['tree_true'],dic[i]['tree_pred'] = [],[]\n",
    "    dic[i]['tree_true'] = treemaker.sents2tree(dic[i]['directions'])\n",
    "    dic[i]['tree_pred'] = treemaker.sents2tree(dic[i]['generated_instr'])\n",
    "    tree1 = build_tree(dic[i]['tree_true'])\n",
    "    tree2 = build_tree(dic[i]['tree_pred'])\n",
    "    dic[i]['#tree_dist'] = tree_distance(tree1, tree2)\n",
    "    len_true = sum([len(sent['ingredient']) + 1 for sent in dic[i]['tree_true']])\n",
    "    len_pred = sum([len(sent['ingredient']) + 1 for sent in dic[i]['tree_pred']])\n",
    "    BP = len_pred/len_true\n",
    "    dic[i]['#BP'] = BP if BP < 1 else 1\n",
    "### 333k full\n",
    "df2 = pd.DataFrame.from_dict(dic, orient = 'index')\n",
    "temp = df2[[col for col in df2.columns if '#' in col]].iloc[ls].mean()\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load ../../to_gpt2/generation_28k_sorted/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [01:14<00:00,  6.51it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "#tree_dist    40.422150\n",
       "#BP            0.263393\n",
       "dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1min 17s\n"
     ]
    }
   ],
   "source": [
    "filename = '../../to_gpt2/generation_28k_sorted/'\n",
    "ls = load_dir_data(filename)\n",
    "for i in tqdm.tqdm(ls): \n",
    "    dic[i]['tree_true'],dic[i]['tree_pred'] = [],[]\n",
    "    dic[i]['tree_true'] = treemaker.sents2tree(dic[i]['directions'])\n",
    "    dic[i]['tree_pred'] = treemaker.sents2tree(dic[i]['generated_instr'][:2])\n",
    "    tree1 = build_tree(dic[i]['tree_true'])\n",
    "    tree2 = build_tree(dic[i]['tree_pred'])\n",
    "    dic[i]['#tree_dist'] = tree_distance(tree1, tree2)\n",
    "    len_true = sum([len(sent['ingredient']) + 1 for sent in dic[i]['tree_true']])\n",
    "    len_pred = sum([len(sent['ingredient']) + 1 for sent in dic[i]['tree_pred']])\n",
    "    BP = len_pred/len_true\n",
    "    dic[i]['#BP'] = BP if BP < 1 else 1\n",
    "### 333k full\n",
    "df2 = pd.DataFrame.from_dict(dic, orient = 'index')\n",
    "temp = df2[[col for col in df2.columns if '#' in col]].iloc[ls].mean()\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load ../../to_gpt2/generation_333k_sorted/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [01:13<00:00,  6.90it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "#tree_dist    39.816640\n",
       "#BP            0.274905\n",
       "dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1min 16s\n"
     ]
    }
   ],
   "source": [
    "filename = '../../to_gpt2/generation_333k_sorted/'\n",
    "ls = load_dir_data(filename)\n",
    "for i in tqdm.tqdm(ls): \n",
    "    dic[i]['tree_true'],dic[i]['tree_pred'] = [],[]\n",
    "    dic[i]['tree_true'] = treemaker.sents2tree(dic[i]['directions'])\n",
    "    dic[i]['tree_pred'] = treemaker.sents2tree(dic[i]['generated_instr'][:2])\n",
    "    tree1 = build_tree(dic[i]['tree_true'])\n",
    "    tree2 = build_tree(dic[i]['tree_pred'])\n",
    "    dic[i]['#tree_dist'] = tree_distance(tree1, tree2)\n",
    "    len_true = sum([len(sent['ingredient']) + 1 for sent in dic[i]['tree_true']])\n",
    "    len_pred = sum([len(sent['ingredient']) + 1 for sent in dic[i]['tree_pred']])\n",
    "    BP = len_pred/len_true\n",
    "    dic[i]['#BP'] = BP if BP < 1 else 1\n",
    "### 333k full\n",
    "df2 = pd.DataFrame.from_dict(dic, orient = 'index')\n",
    "temp = df2[[col for col in df2.columns if '#' in col]].iloc[ls].mean()\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 46.6 ms\n"
     ]
    }
   ],
   "source": [
    "def avg_embedding(tree):\n",
    "    '''\n",
    "    [{'word': 'stir', 'ingredient': ['ketchup', 'mustard', 'plate']},\n",
    "    {'word': 'stir', 'ingredient': ['']}]\n",
    "    '''\n",
    "    words = [ing for line in tree for ing in line['ingredient'] if ing]\n",
    "    words += [line['word'] for line in tree]\n",
    "    X = np.array([gensim_model.get_vector(word) for word in words if word in vocabulary])\n",
    "    return X.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load ../../to_gpt2/generation_28k_sorted/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [01:32<00:00,  5.65it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "@cosine dist    0.221484\n",
       "dtype: float64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1min 35s\n"
     ]
    }
   ],
   "source": [
    "filename = '../../to_gpt2/generation_28k_sorted/'\n",
    "ls = load_dir_data(filename)\n",
    "for i in tqdm.tqdm(ls): \n",
    "    dic[i]['tree_true'],dic[i]['tree_pred'] = [],[]\n",
    "    dic[i]['tree_true'] = treemaker.sents2tree(dic[i]['directions'])\n",
    "    dic[i]['tree_pred'] = treemaker.sents2tree(dic[i]['generated_instr'])\n",
    "    dic[i]['@cosine dist'] = cosine_distance(avg_embedding(dic[i]['tree_true']), avg_embedding(dic[i]['tree_pred']))\n",
    "\n",
    "df2 = pd.DataFrame.from_dict(dic, orient = 'index')\n",
    "temp = df2[[col for col in df2.columns if '@' in col]].iloc[ls].mean()\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load ../../to_gpt2/generation_333k_sorted/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [01:30<00:00,  5.61it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "@cosine dist    0.229657\n",
       "dtype: float64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1min 33s\n"
     ]
    }
   ],
   "source": [
    "filename = '../../to_gpt2/generation_333k_sorted/'\n",
    "ls = load_dir_data(filename)\n",
    "for i in tqdm.tqdm(ls): \n",
    "    dic[i]['tree_true'],dic[i]['tree_pred'] = [],[]\n",
    "    dic[i]['tree_true'] = treemaker.sents2tree(dic[i]['directions'])\n",
    "    dic[i]['tree_pred'] = treemaker.sents2tree(dic[i]['generated_instr'])\n",
    "    dic[i]['@cosine dist'] = cosine_distance(avg_embedding(dic[i]['tree_true']), avg_embedding(dic[i]['tree_pred']))\n",
    "\n",
    "df2 = pd.DataFrame.from_dict(dic, orient = 'index')\n",
    "temp = df2[[col for col in df2.columns if '@' in col]].iloc[ls].mean()\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
