{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Because the field of description looks noisy, we decides to conduct 3 fields generation instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 18.1 µs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "%load_ext autotime\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "# if cannot import the modules, add the parent directory to system path might help\n",
    "\n",
    "import os\n",
    "import sys\n",
    "parent_dir = os.path.abspath(os.getcwd()+'/..')+'/'\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "from utils.path import dir_HugeFiles\n",
    "from utils.preprocessing import load\n",
    "from utils.words import make_corpus_0, get_wordcount_list\n",
    "from utils.save import make_dir, save_pickle, load_pickle, auto_save_csv, print_time\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "\n",
    "#dir_save = os.path.normpath(dir_HugeFiles+'dph/dic_20190607.pickle')\n",
    "#dic = load(dir_save)\n",
    "random_seed = 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exist ../big_data/dic_20190830.pickle\n",
      "drop 46 recipes with less than 2 ingredients\n",
      "furthur drop 1026 recipes with less than 2 instructions\n",
      "drop 0 recipes with no description\n",
      "now we are using recipe54k 54076\n",
      "time: 2.39 s\n"
     ]
    }
   ],
   "source": [
    "dic = load(dir_save = '../big_data/dic_20190830.pickle')\n",
    "\n",
    "ls = [i for i,v in dic.items() if len(v['ingredients'])>1]\n",
    "print('drop %d recipes with less than 2 ingredients' %(len(dic)-len(ls)))\n",
    "ls = [i for i in ls if len(dic[i]['directions'])>1]\n",
    "print('furthur drop %d recipes with less than 2 instructions' %(len(dic)-len(ls)))\n",
    "desc = [i for i in ls if len(dic[i]['description'])<1]\n",
    "print('drop %d recipes with no description' %(len(desc)))\n",
    "print('now we are using recipe54k %d' % len(ls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = range(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 35.4 ms\n"
     ]
    }
   ],
   "source": [
    "def reverse(text):\n",
    "    # replace things in brace\n",
    "    text = re.sub(r'\\([^)]*\\)', '', text)\n",
    "\n",
    "    # remove space before punct\n",
    "    text = re.sub(r'\\s([?.!,\"](?:\\s|$))', r'\\1', text)\n",
    "    \n",
    "    # remove consecutive sap\n",
    "    text = text.replace('  ', ' ')\n",
    "    return text\n",
    "\n",
    "def txt(v, fields, mode = 'train'):\n",
    "    '''\n",
    "    fields: an order list, the last is the field to predict\n",
    "    mode: test/train, return string X, y or X+y\n",
    "    '''\n",
    "    to_write = ''\n",
    "    for field in fields:\n",
    "        if field == 'title':\n",
    "            name = [reverse(sent) for sent in v['name']]\n",
    "            to_write += ' <start-title>'+' '.join(name)+' <end-title>'\n",
    "        if field == 'ingredients':\n",
    "            ingredients = [reverse(sent) for sent in v['ingredients']]\n",
    "            to_write += ' <start-ingredients>'+'$'.join(ingredients)+'$ <end-ingredients>'\n",
    "        if field == 'directions':\n",
    "            directions = [reverse(sent) for sent in v['directions']]\n",
    "            to_write += ' <start-directions>'+' '.join(directions)+' <end-directions>'\n",
    "                                                     \n",
    "    if mode == 'train':\n",
    "        return to_write\n",
    "                                                     \n",
    "    elif mode == 'test':\n",
    "        field_to_predict = '<start-%s>'%fields[-1]\n",
    "        to_X, to_y = to_write.split(field_to_predict)\n",
    "        return to_X+field_to_predict, to_y\n",
    "\n",
    "class to_gpt2:\n",
    "    def __init__(self, dic, ls):\n",
    "        ls_train, self.ls_test, _, __ = train_test_split(ls, ls, test_size = 0.2, random_state = random_seed, shuffle = True)\n",
    "        self.ls_train, self.ls_val, _, __ = train_test_split(ls_train, ls_train, test_size = 0.25, random_state = random_seed , shuffle = True)\n",
    "        self.dic = dic\n",
    "    def train(self, ls, filename, overwrite = False, is_val = False):\n",
    "        to_write = ''\n",
    "        for i, v in self.dic.items():\n",
    "            if i in ls:      \n",
    "                self.save(filename+'%d'%(i)+'d.txt', txt(v, ['title','ingredients','directions']), overwrite)\n",
    "                self.save(filename+'%d'%(i)+'i.txt', txt(v, ['title','directions','ingredients']), overwrite)\n",
    "                self.save(filename+'%d'%(i)+'t.txt', txt(v, ['ingredients','directions','title']), overwrite)\n",
    "                \n",
    "    def train_reduce(self, ls, filename, overwrite = False, is_val = False):\n",
    "        to_write = ''\n",
    "        for i, v in self.dic.items():\n",
    "            if i in ls:      \n",
    "                self.save(filename+'%d'%(i)+'d.txt', txt(v, ['title','ingredients','directions']), overwrite)\n",
    "                \n",
    "    def test(self, ls, filename, overwrite = False, is_val = False):\n",
    "        to_write = ''\n",
    "        for i, v in self.dic.items():\n",
    "            if i in ls:\n",
    "                self.save(filename+'X/%d'%(i)+'d.txt', txt(v, ['title','ingredients','directions'], mode = 'test')[0], overwrite)\n",
    "                self.save(filename+'X/%d'%(i)+'i.txt', txt(v, ['title','directions','ingredients'], mode = 'test')[0], overwrite)\n",
    "                self.save(filename+'X/%d'%(i)+'t.txt', txt(v, ['ingredients','directions','title'], mode = 'test')[0], overwrite)\n",
    "                \n",
    "                self.save(filename+'y/%d'%(i)+'d.txt', txt(v, ['title','ingredients','directions'], mode = 'test')[1], overwrite)\n",
    "                self.save(filename+'y/%d'%(i)+'i.txt', txt(v, ['title','directions','ingredients'], mode = 'test')[1], overwrite)\n",
    "                self.save(filename+'y/%d'%(i)+'t.txt', txt(v, ['ingredients','directions','title'], mode = 'test')[1], overwrite)\n",
    "                \n",
    "                self.save(filename+'Xy/%d'%(i)+'d.txt', txt(v, ['title','ingredients','directions']), overwrite)\n",
    "                self.save(filename+'Xy/%d'%(i)+'i.txt', txt(v, ['title','directions','ingredients']), overwrite)\n",
    "                self.save(filename+'Xy/%d'%(i)+'t.txt', txt(v, ['ingredients','directions','title']), overwrite)\n",
    "                \n",
    "    def fast_export(self, filename, overwrite = False):\n",
    "        self.train_reduce(self.ls_train, filename+'sample_train/', overwrite = overwrite)\n",
    "        self.train_reduce(self.ls_val, filename+'sample_val/',overwrite = overwrite)\n",
    "        self.test(self.ls_test, filename+'sample_test/', overwrite = overwrite)\n",
    "    def save(self, filename, to_write, overwrite = False):\n",
    "        make_dir(filename)\n",
    "        if os.path.isfile(filename) == True and overwrite == False:\n",
    "            print('already exists'+filename)\n",
    "        else:    \n",
    "            with open(filename,'w') as f:\n",
    "                f.write('%s' % to_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = to_gpt2(dic, ls)\n",
    "model.fast_export('../../to_gpt2/recipe54k_0916/',overwrite = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make dir\n",
      "make dir\n",
      "make dir\n",
      "time: 1min 48s\n"
     ]
    }
   ],
   "source": [
    "model = to_gpt2(dic, ls)\n",
    "model.test(model.ls_train, '../../to_gpt2/recipe54k_0916_/', overwrite = False, is_val = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Options: <br>\n",
    "1 Zip everything and use scp to transfer the files <br>\n",
    "2 run on DGX server (faster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from collections import Counter\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = to_gpt2(dic, ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exatract_root(dic, ls):\n",
    "    '''\n",
    "    dic: dict\n",
    "    ls: list\n",
    "    if len(ls) = 30k, it will take around 1 hour on eta 13\n",
    "    '''\n",
    "    root_verbs = []\n",
    "    for i, v in tqdm.tqdm(dic.items()):\n",
    "        if i in ls:\n",
    "            for sent in v['directions']:\n",
    "                doc = nlp(sent)\n",
    "                for token in doc:\n",
    "                    if token.dep_ == 'ROOT' and token.pos_ == 'VERB':\n",
    "                        root_verbs.append(token.text)\n",
    "    return Counter(root_verbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55102/55102 [59:49<00:00,  8.92it/s]\n"
     ]
    }
   ],
   "source": [
    "root_counts = exatract_root(dic, model.ls_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pickle(obj = root_counts, filename='../data/root_counts.pickle', overwrite=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3 tablespoons olive oil , divided , or more as needed',\n",
       " '1 shallot , minced',\n",
       " '3/4 cup chopped hazelnuts',\n",
       " '2 3/4 cups broccoli florets',\n",
       " '1 tablespoon finely chopped fresh parsley',\n",
       " '1 teaspoon chopped fresh dill',\n",
       " '1 pinch salt and freshly ground black pepper to taste',\n",
       " '1 pinch ground nutmeg']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic[8]['ingredients']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['heat 1 tablespoon olive oil in a skillet and cook shallot until soft and translucent , about 5 minutes .',\n",
       " 'add hazelnuts and cook until toasted , about 2 minutes .',\n",
       " 'remove from heat and cool for 10 minutes .',\n",
       " 'meanwhile , bring a pot of lightly salted water to a boil and cook broccoli until softened , about 3 minutes .',\n",
       " 'drain and rinse under cold water .',\n",
       " 'drain well .',\n",
       " 'combine shallot hazelnut mixture , broccoli , parsley , and dill in the bowl of a food processor pulse until blended .',\n",
       " 'pour 2 tablespoons olive oil in slowly , with the processor running , until spread is smooth .',\n",
       " 'add more olive oil if needed .',\n",
       " 'season with salt , pepper , and nutmeg .']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic[8]['directions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "x = root_counts\n",
    "y = OrderedDict(x.most_common())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common_words= [word for word, word_count in root_counts.most_common(300)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['add',\n",
       " 'stir',\n",
       " 'preheat',\n",
       " 'bake',\n",
       " 'pour',\n",
       " 'remove',\n",
       " 'combine',\n",
       " 'mix',\n",
       " 'cook',\n",
       " 'bring',\n",
       " 'place',\n",
       " 'cover',\n",
       " 'beat',\n",
       " 'sprinkle',\n",
       " 'spread',\n",
       " 'drain',\n",
       " 'reduce',\n",
       " 'serve',\n",
       " 'cut',\n",
       " 'whisk',\n",
       " 'transfer',\n",
       " 'heat',\n",
       " 'melt',\n",
       " 'let',\n",
       " 'grease',\n",
       " 'set',\n",
       " 'fold',\n",
       " 'roll',\n",
       " 'arrange',\n",
       " 'refrigerate',\n",
       " 'allow',\n",
       " 'toss',\n",
       " 'turn',\n",
       " 'simmer',\n",
       " 'return',\n",
       " 'repeat',\n",
       " 'divide',\n",
       " 'continue',\n",
       " 'blend',\n",
       " 'line',\n",
       " 'make',\n",
       " 'fill',\n",
       " 'sift',\n",
       " 'chill',\n",
       " 'drop',\n",
       " 'be',\n",
       " 'use',\n",
       " 'spoon',\n",
       " 'read',\n",
       " 'spray',\n",
       " 'is',\n",
       " 'slice',\n",
       " 'brush',\n",
       " 'cream',\n",
       " 'put',\n",
       " 'wrap',\n",
       " 'fry',\n",
       " 'prepare',\n",
       " 'press',\n",
       " 'dip',\n",
       " 'garnish',\n",
       " 'flip',\n",
       " 'form',\n",
       " 'lay',\n",
       " 'drizzle',\n",
       " 'discard',\n",
       " 'rinse',\n",
       " 'shape',\n",
       " 'mash',\n",
       " 'dissolve',\n",
       " 'crumble',\n",
       " 'rub',\n",
       " 'store',\n",
       " 'taste',\n",
       " 'increase',\n",
       " 'peel',\n",
       " 'stand',\n",
       " 'boil',\n",
       " 'saute',\n",
       " 'chop',\n",
       " 'remaining',\n",
       " 'coat',\n",
       " 'top',\n",
       " 'soak',\n",
       " 'scoop',\n",
       " 'knead',\n",
       " 'squeeze',\n",
       " 'run',\n",
       " 'scrape',\n",
       " 'keep',\n",
       " 'break',\n",
       " 'comes',\n",
       " 'freeze',\n",
       " 'marinate',\n",
       " 'butter',\n",
       " 'flatten',\n",
       " 'take',\n",
       " 'strain',\n",
       " 'are',\n",
       " 'seal',\n",
       " 'using',\n",
       " 'reserve',\n",
       " 'shake',\n",
       " 'broil',\n",
       " 'uncover',\n",
       " 'oil',\n",
       " 'select',\n",
       " 'adjust',\n",
       " 'leave',\n",
       " 'dredge',\n",
       " 'invert',\n",
       " 'cooked',\n",
       " 'trim',\n",
       " 'watch',\n",
       " 'pat',\n",
       " 'done',\n",
       " 'scatter',\n",
       " 'shred',\n",
       " 'punch',\n",
       " 'melted',\n",
       " 'wipe',\n",
       " 'uncovered',\n",
       " 'grind',\n",
       " 'desired',\n",
       " 'poke',\n",
       " 'roast',\n",
       " 'unroll',\n",
       " 'have',\n",
       " 'unlock',\n",
       " 'frost',\n",
       " 'layer',\n",
       " 'wash',\n",
       " 'whip',\n",
       " 'crack',\n",
       " 'browned',\n",
       " 'pack',\n",
       " 'ladle',\n",
       " 'need',\n",
       " 'batter',\n",
       " 'check',\n",
       " 'brown',\n",
       " 'lift',\n",
       " 'push',\n",
       " 'pull',\n",
       " 'pinch',\n",
       " 'skim',\n",
       " 'hold',\n",
       " 'grill',\n",
       " 'covered',\n",
       " 'move',\n",
       " 'separate',\n",
       " 'crush',\n",
       " 'assemble',\n",
       " 'insert',\n",
       " 'start',\n",
       " 'decorate',\n",
       " 'pierce',\n",
       " 'moisten',\n",
       " 'softened',\n",
       " 'enjoy',\n",
       " 'puree',\n",
       " 'measure',\n",
       " 'distribute',\n",
       " 'stack',\n",
       " 'cool',\n",
       " 'sear',\n",
       " 'baste',\n",
       " 'loosen',\n",
       " 'open',\n",
       " 'close',\n",
       " 'toast',\n",
       " 'prick',\n",
       " 'sit',\n",
       " 'unwrap',\n",
       " 'raise',\n",
       " 'cooled',\n",
       " 'makes',\n",
       " 'deflate',\n",
       " 'slide',\n",
       " 'work',\n",
       " 'stirring',\n",
       " 'swirl',\n",
       " 'dust',\n",
       " 'evaporated',\n",
       " 'working',\n",
       " 'split',\n",
       " 'stuff',\n",
       " 'finish',\n",
       " 'sterilize',\n",
       " 'note',\n",
       " 'tear',\n",
       " 'gather',\n",
       " 'thicken',\n",
       " 'begin',\n",
       " 'reheat',\n",
       " 'fit',\n",
       " 'served',\n",
       " 'do',\n",
       " 'layering',\n",
       " 'pulse',\n",
       " 'stick',\n",
       " 'pick',\n",
       " 'switch',\n",
       " 'tie',\n",
       " 'replace',\n",
       " 'look',\n",
       " 'cooking',\n",
       " 'warm',\n",
       " 'heated',\n",
       " 'lower',\n",
       " 's',\n",
       " 'dot',\n",
       " 'score',\n",
       " 'come',\n",
       " 'halve',\n",
       " 'reads',\n",
       " 'rolled',\n",
       " 'pound',\n",
       " 'attach',\n",
       " 'secure',\n",
       " 'rotate',\n",
       " 'want',\n",
       " 'tuck',\n",
       " 'create',\n",
       " 'leaves',\n",
       " 'crimp',\n",
       " 'release',\n",
       " 'reached',\n",
       " 'stream',\n",
       " 'immerse',\n",
       " 'submerge',\n",
       " 'microwave',\n",
       " 'absorbed',\n",
       " 'made',\n",
       " 'reserved',\n",
       " 'pipe',\n",
       " 'coated',\n",
       " 'dice',\n",
       " 'turning',\n",
       " 'flour',\n",
       " 'chopped',\n",
       " 'wait',\n",
       " 'soften',\n",
       " 'tap',\n",
       " 'rise',\n",
       " 'like',\n",
       " 'try',\n",
       " 'grate',\n",
       " 'frozen',\n",
       " 'eat',\n",
       " 'smooth',\n",
       " 'begins',\n",
       " 'used',\n",
       " 'finished',\n",
       " 'ends',\n",
       " 'overbake',\n",
       " 'burn',\n",
       " 'overmix',\n",
       " 'test',\n",
       " 'whipped',\n",
       " 'pass',\n",
       " 'give',\n",
       " 'skewer',\n",
       " 'dissolved',\n",
       " 'process',\n",
       " 'unmold',\n",
       " 'build',\n",
       " 'carve',\n",
       " 'see',\n",
       " 'stored',\n",
       " 'unfold',\n",
       " 'thaw',\n",
       " 'sliced',\n",
       " 'filled',\n",
       " 'boiling',\n",
       " 'apply',\n",
       " 'appear',\n",
       " 'become',\n",
       " 'dipped',\n",
       " 'draw',\n",
       " 'remain',\n",
       " 'added',\n",
       " 'stop',\n",
       " 'save',\n",
       " 'clean',\n",
       " 'blanch',\n",
       " 'follow',\n",
       " 'steam',\n",
       " 'twist',\n",
       " 'dry',\n",
       " 'stretch',\n",
       " 'slip',\n",
       " 'refrigerated',\n",
       " 'mince',\n",
       " 'stems',\n",
       " 'starting',\n",
       " 'prepared',\n",
       " 'edges',\n",
       " 'reaches',\n",
       " 'tilt']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_common_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
