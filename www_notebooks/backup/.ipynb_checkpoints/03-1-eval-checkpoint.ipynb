{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 9.54 µs\n",
      "The autotime extension is already loaded. To reload it, use:\n",
      "  %reload_ext autotime\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "time: 33.6 s\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "%load_ext autotime\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# if cannot import the modules, add the parent directory to system path might help\n",
    "import os, tqdm, sys\n",
    "parent_dir = os.path.abspath(os.getcwd()+'/..')+'/'\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "from utils.path import dir_HugeFiles\n",
    "from utils.save import make_dir, save_pickle, load_pickle, save\n",
    "from utils.tree import instr2tree, tree_distance, build_tree, stem\n",
    "from utils.evaluation import metrics, spacy_extension\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "treemaker = instr2tree()\n",
    "sp = spacy_extension()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 82.6 ms\n"
     ]
    }
   ],
   "source": [
    "class evaluation:\n",
    "    def __init__(self, filename, tag):\n",
    "        self.dic = self.load_dic({}, filename, tag)\n",
    "        self.ori = tag\n",
    "        self.gens = []\n",
    "        #from utils.evaluation import metrics\n",
    "    '''\n",
    "    loading data\n",
    "    '''\n",
    "    def append_dic(self, filename, tag):\n",
    "        if tag in self.gens:\n",
    "            print('already exist, will not load again')\n",
    "            self.gen = tag\n",
    "        else:\n",
    "            self.dic = self.load_dic(self.dic, filename, tag)\n",
    "            self.gen = tag\n",
    "            self.gens += [tag]\n",
    "        \n",
    "    def load_dic(self, dic, filename, tag):\n",
    "        if os.path.isdir(filename):\n",
    "            print('load', filename)\n",
    "            for (dirpath, _, fnames) in os.walk(filename):\n",
    "                for fname in fnames:\n",
    "                    path = os.path.join(dirpath, fname)\n",
    "                    with open(path, 'r') as fp:\n",
    "                        raw_text = fp.read()\n",
    "                        raw_text = self.remove_end(raw_text)\n",
    "\n",
    "                    name, field = int(fname[:-5]), fname[-5]\n",
    "\n",
    "                    if name not in dic.keys() and field in ['d','i']:\n",
    "                        dic.update({name: {}})\n",
    "\n",
    "                    if field == 'd':\n",
    "                        dic[name].update({'%s_instr'%(tag): raw_text})\n",
    "\n",
    "                    if field == 'i':\n",
    "                        raw_text = self.reverse_list(raw_text.split('$'))\n",
    "                        dic[name].update({'%s_ingr'%(tag): raw_text})\n",
    "        return dic\n",
    "    \n",
    "    '''\n",
    "    exporting data\n",
    "    '''\n",
    "    def to_bleu(self):\n",
    "        to_write = {'%s_i'%(self.ori):'',\n",
    "                    '%s_i'%(self.gen):'',\n",
    "                    '%s_d'%(self.ori):'',\n",
    "                    '%s_d'%(self.gen):''}\n",
    "        \n",
    "        for i, v in self.dic.items():\n",
    "            to_write['%s_i'%(self.ori)] += self.add_space(' $ '.join(v['%s_ingr'%(self.ori)]))+ ' $ \\n'\n",
    "            to_write['%s_i'%(self.gen)] += self.add_space(' $ '.join(v['%s_ingr'%(self.gen)])) + ' $ \\n'\n",
    "            \n",
    "            to_write['%s_d'%(self.ori)] += self.add_space(v['%s_instr'%(self.ori)])+ '\\n'\n",
    "            to_write['%s_d'%(self.gen)] += self.add_space(v['%s_instr'%(self.gen)])+ '\\n'\n",
    "        \n",
    "        for k, v in to_write.items():\n",
    "            save('../../to_gpt2/generation_%s.txt'%(k), v ,overwrite = True)\n",
    "        !eval {\"perl multi-bleu.perl ../../to_gpt2/generation_%s_i.txt < ../../to_gpt2/generation_%s_i.txt\" %(self.ori, self.gen)}\n",
    "        !eval {\"perl multi-bleu.perl ../../to_gpt2/generation_%s_d.txt < ../../to_gpt2/generation_%s_d.txt\" %(self.ori, self.gen)}\n",
    "    \n",
    "        !eval {\"rouge -f ../../to_gpt2/generation_%s_i.txt ../../to_gpt2/generation_%s_i.txt --avg\"%(self.ori, self.gen)}\n",
    "        !eval {\"rouge -f ../../to_gpt2/generation_%s_d.txt ../../to_gpt2/generation_%s_d.txt --avg\"%(self.ori, self.gen)}\n",
    "        \n",
    "        print()\n",
    "\n",
    "    def ingr_f1_freq(self, root = False):\n",
    "        value = []\n",
    "        for i, v in tqdm.tqdm(self.dic.items()):\n",
    "            true, pred = v['%s_ingr'%(self.ori)], v['%s_ingr'%(self.gen)]\n",
    "            if root:\n",
    "                true, pred = sp.root(true), sp.root(pred)\n",
    "            scores = metrics(true, pred)\n",
    "            value.append(scores.f1_freq())\n",
    "        avg = sum(value)/len(value)\n",
    "        print(avg)\n",
    "        return avg\n",
    "    '''\n",
    "    instruction evaluation\n",
    "    '''\n",
    "    def instr_tree(self, stem_only = False):\n",
    "        value = []\n",
    "        for i, v in tqdm.tqdm(self.dic.items()):\n",
    "            ori_instr, gen_instr = v['%s_instr'%(self.ori)], v['%s_instr'%(self.gen)]\n",
    "            score = self.norm_dist(ori_instr, gen_instr, stem_only = stem_only)\n",
    "            value.append(score)\n",
    "        avg = sum(value)/len(value)\n",
    "        print(avg)\n",
    "        return avg\n",
    "\n",
    "    def state_f1_freq(self):\n",
    "        value = []\n",
    "        for i, v in tqdm.tqdm(self.dic.items()):\n",
    "            true, pred = v['%s_instr'%(self.ori)], v['%s_instr'%(self.gen)]\n",
    "            true, pred = sp.match_state(true), sp.match_state(pred)\n",
    "            scores = metrics(true, pred)\n",
    "            value.append(scores.f1_freq())\n",
    "        avg = sum(value)/len(value)\n",
    "        print(avg)\n",
    "        return avg\n",
    "    \n",
    "    def verb_f1_freq(self):\n",
    "        value = []\n",
    "        for i, v in tqdm.tqdm(self.dic.items()):\n",
    "            true, pred = v['%s_instr'%(self.ori)], v['%s_instr'%(self.gen)]\n",
    "            true, pred = sp.instructions(true)[1], sp.instructions(pred)[1]\n",
    "            scores = metrics(true, pred)\n",
    "            value.append(scores.f1_freq())\n",
    "        avg = sum(value)/len(value)\n",
    "        print(avg)\n",
    "        return avg\n",
    "    \n",
    "    '''\n",
    "    cleaning data\n",
    "    '''\n",
    "    def remove_end(self, text):\n",
    "        return text.replace('\\n','').split('<')[0]\n",
    "    \n",
    "    def reverse(self, text):\n",
    "        '''\n",
    "        Important data cleaning before NY times parser\n",
    "        '''\n",
    "        # replace things in brace\n",
    "        text = re.sub(r'\\([^)]*\\)', '', text)\n",
    "\n",
    "        # remove space before punct\n",
    "        text = re.sub(r'\\s([?.!,\"](?:\\s|$))', r'\\1', text)\n",
    "\n",
    "        # remove consecutive spaces\n",
    "        text = re.sub(' +',' ',text).strip()\n",
    "        return text\n",
    "    \n",
    "    def reverse_list(self, listoftext):\n",
    "        output = []\n",
    "        for text in listoftext:\n",
    "            rev = self.reverse(text)\n",
    "            if rev:\n",
    "                output.append(rev)\n",
    "        return output\n",
    "    \n",
    "    def add_space(self, line):\n",
    "        # add space before punct\n",
    "        line = re.sub('([.,!?()])', r' \\1 ', line)\n",
    "        line = re.sub('\\s{2,}', ' ', line)\n",
    "        return line\n",
    "    \n",
    "    '''\n",
    "    tree edit distance\n",
    "    '''\n",
    "\n",
    "    def str2tree(self, instr, stem_only):\n",
    "        instr = [x for x in instr.split('. ') if x]\n",
    "        instr = treemaker.sents2tree(instr)\n",
    "        if stem_only:\n",
    "            instr = stem(instr)\n",
    "        n_nodes = sum([len(line['ingredient']) +1 for line in instr])\n",
    "        return build_tree(instr), n_nodes\n",
    "\n",
    "    def norm_dist(self, ori_instr, gen_instr, stem_only):\n",
    "        '''\n",
    "        Args: ori_instr: str\n",
    "        Args: gen_instr: str\n",
    "        '''\n",
    "        ori_tree, ori_nodes = self.str2tree(ori_instr, stem_only = stem_only)\n",
    "        gen_tree, gen_nodes = self.str2tree(gen_instr, stem_only = stem_only)\n",
    "        tree_dist = tree_distance(ori_tree, gen_tree)\n",
    "        normed = tree_dist/(ori_nodes+gen_nodes)\n",
    "        return normed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load ../../to_gpt2/recipe1M_1118/val/y/\n",
      "load ../../to_gpt2/generation_201911118_k1_val/\n",
      "load ../../to_gpt2/generation_201911118_k3_val/\n",
      "load ../../to_gpt2/generation_201911118_k5_val/\n",
      "load ../../to_gpt2/generation_201911118_k10_val/\n",
      "load ../../to_gpt2/generation_201911118_k30_val/\n",
      "load ../../to_gpt2/generation_201911118_p99_val/\n",
      "time: 9.93 s\n"
     ]
    }
   ],
   "source": [
    "data = evaluation('../../to_gpt2/recipe1M_1118/val/y/', 'ori')\n",
    "data.append_dic('../../to_gpt2/generation_201911118_k1_val/', 'k1')\n",
    "data.append_dic('../../to_gpt2/generation_201911118_k3_val/', 'k3')\n",
    "data.append_dic('../../to_gpt2/generation_201911118_k5_val/', 'k5')\n",
    "data.append_dic('../../to_gpt2/generation_201911118_k10_val/', 'k10')\n",
    "data.append_dic('../../to_gpt2/generation_201911118_k30_val/', 'k30')\n",
    "data.append_dic('../../to_gpt2/generation_201911118_p99_val/', 'p99')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load ../../to_gpt2/recipe1M_1118/val/y/\n",
      "load ../../to_gpt2/generation_201911118_k5_val/\n",
      "117_k5\n",
      "saved ../../to_gpt2/generation_ori_i.txt\n",
      "saved ../../to_gpt2/generation_117_k5_i.txt\n",
      "saved ../../to_gpt2/generation_ori_d.txt\n",
      "saved ../../to_gpt2/generation_117_k5_d.txt\n",
      "BLEU = 27.73, 70.9/51.2/26.8/10.6 (BP=0.870, ratio=0.878, hyp_len=89249, ref_len=101657)\n",
      "It is not advisable to publish scores from multi-bleu.perl.  The scores depend on your tokenizer, which is unlikely to be reproducible from your paper or consistent across research groups.  Instead you should detokenize then use mteval-v14.pl, which has a standard tokenization.  Scores from multi-bleu.perl can still be used for internal purposes when you have a consistent tokenizer.\n",
      "BLEU = 8.17, 49.9/16.4/5.8/2.3 (BP=0.796, ratio=0.814, hyp_len=425065, ref_len=522308)\n",
      "It is not advisable to publish scores from multi-bleu.perl.  The scores depend on your tokenizer, which is unlikely to be reproducible from your paper or consistent across research groups.  Instead you should detokenize then use mteval-v14.pl, which has a standard tokenization.  Scores from multi-bleu.perl can still be used for internal purposes when you have a consistent tokenizer.\n",
      "{\n",
      "  \"rouge-1\": {\n",
      "    \"f\": 0.6038661510025992,\n",
      "    \"p\": 0.5686878629896001,\n",
      "    \"r\": 0.694097089837656\n",
      "  },\n",
      "  \"rouge-2\": {\n",
      "    \"f\": 0.4795655268981533,\n",
      "    \"p\": 0.4582550924639056,\n",
      "    \"r\": 0.5434373857006771\n",
      "  },\n",
      "  \"rouge-l\": {\n",
      "    \"f\": 0.3352041649777611,\n",
      "    \"p\": 0.33586808927298295,\n",
      "    \"r\": 0.41606269993436723\n",
      "  }\n",
      "}\n",
      "{\n",
      "  \"rouge-1\": {\n",
      "    \"f\": 0.42085278257601927,\n",
      "    \"p\": 0.4038761498110132,\n",
      "    \"r\": 0.4868177082884032\n",
      "  },\n",
      "  \"rouge-2\": {\n",
      "    \"f\": 0.12063683827343027,\n",
      "    \"p\": 0.11796532978667465,\n",
      "    \"r\": 0.14132459116171703\n",
      "  },\n",
      "  \"rouge-l\": {\n",
      "    \"f\": 0.3623998227107736,\n",
      "    \"p\": 0.37402187883402294,\n",
      "    \"r\": 0.45107927405471415\n",
      "  }\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "117_k5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 77/4000 [00:04<04:05, 15.97it/s]/data/yueliu/RecipeAnalytics_201906/AA6/utils/evaluation.py:34: UndefinedMetricWarning: input/inputs may be empty\n",
      "  self.warn()\n",
      "100%|██████████| 4000/4000 [04:10<00:00, 14.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6254981632223141\n",
      "time: 6min 45s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data = evaluation('../../to_gpt2/recipe1M_1118/val/y/', 'ori')\n",
    "data.append_dic('../../to_gpt2/generation_201911118_k5_val/', '117_k5')\n",
    "for tag in data.gens:\n",
    "    print(tag)\n",
    "    data.gen = tag\n",
    "    data.to_bleu()\n",
    "for tag in data.gens:\n",
    "    print(tag)\n",
    "    data.gen = tag\n",
    "    data.ingr_f1_freq(root=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = evaluation('../../to_gpt2/recipe1M_1118/val/y/', 'ori')\n",
    "data.append_dic('../../to_gpt2/generation_201911118_k1_val/', '117_k1')\n",
    "data.append_dic('../../to_gpt2/generation_201911118_k3_val/', '117_k3')\n",
    "data.append_dic('../../to_gpt2/generation_201911118_k5_val/', '117_k5')\n",
    "\n",
    "for tag in data.gens:\n",
    "    print(tag)\n",
    "    data.gen = tag\n",
    "    data.to_bleu()\n",
    "for tag in data.gens:\n",
    "    print(tag)\n",
    "    data.gen = tag\n",
    "    data.ingr_f1_freq(root=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load ../../to_gpt2/recipe1M_1118/val/y/\n",
      "load ../../to_gpt2/generation_201911118_k1_val/\n",
      "load ../../to_gpt2/generation_201911118_k3_val/\n",
      "load ../../to_gpt2/generation_201911118_k5_val/\n",
      "time: 5.74 s\n"
     ]
    }
   ],
   "source": [
    "data = evaluation('../../to_gpt2/recipe1M_1118/val/y/', 'ori')\n",
    "data.append_dic('../../to_gpt2/generation_201911118_k1_val/', '117_k1')\n",
    "data.append_dic('../../to_gpt2/generation_201911118_k3_val/', '117_k3')\n",
    "data.append_dic('../../to_gpt2/generation_201911118_k5_val/', '117_k5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "115.68425"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 103 ms\n"
     ]
    }
   ],
   "source": [
    "tag = 'ori_instr'\n",
    "np.mean([len(v[tag].split(' ')) for i, v in data.dic.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81.81525"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 83.2 ms\n"
     ]
    }
   ],
   "source": [
    "tag = '117_k1_instr'\n",
    "np.mean([len(v[tag].split(' ')) for i, v in data.dic.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87.9125"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 86.1 ms\n"
     ]
    }
   ],
   "source": [
    "tag = '117_k3_instr'\n",
    "np.mean([len(v[tag].split(' ')) for i, v in data.dic.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load ../../to_gpt2/recipe1M_1118/val/y/\n",
      "load ../../to_gpt2/generation_201911118_k1_val/\n",
      "load ../../to_gpt2/generation_201911118_k3_val/\n",
      "load ../../to_gpt2/generation_20191127_k1_val/\n",
      "time: 5.76 s\n"
     ]
    }
   ],
   "source": [
    "data = evaluation('../../to_gpt2/recipe1M_1118/val/y/', 'ori')\n",
    "data.append_dic('../../to_gpt2/generation_201911118_k1_val/', '117_k1')\n",
    "data.append_dic('../../to_gpt2/generation_201911118_k3_val/', '117_k3')\n",
    "data.append_dic('../../to_gpt2/generation_20191127_k1_val/', '345_k1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117_k1\n",
      "saved ../../to_gpt2/generation_ori_i.txt\n",
      "saved ../../to_gpt2/generation_117_k1_i.txt\n",
      "saved ../../to_gpt2/generation_ori_d.txt\n",
      "saved ../../to_gpt2/generation_117_k1_d.txt\n",
      "BLEU = 25.27, 54.9/40.4/21.5/8.6 (BP=1.000, ratio=1.067, hyp_len=108507, ref_len=101657)\n",
      "It is not advisable to publish scores from multi-bleu.perl.  The scores depend on your tokenizer, which is unlikely to be reproducible from your paper or consistent across research groups.  Instead you should detokenize then use mteval-v14.pl, which has a standard tokenization.  Scores from multi-bleu.perl can still be used for internal purposes when you have a consistent tokenizer.\n",
      "BLEU = 10.34, 54.1/21.4/9.4/4.7 (BP=0.689, ratio=0.728, hyp_len=380434, ref_len=522308)\n",
      "It is not advisable to publish scores from multi-bleu.perl.  The scores depend on your tokenizer, which is unlikely to be reproducible from your paper or consistent across research groups.  Instead you should detokenize then use mteval-v14.pl, which has a standard tokenization.  Scores from multi-bleu.perl can still be used for internal purposes when you have a consistent tokenizer.\n",
      "{\n",
      "  \"rouge-1\": {\n",
      "    \"f\": 0.6078115961485572,\n",
      "    \"p\": 0.5425412481741663,\n",
      "    \"r\": 0.7552048899097942\n",
      "  },\n",
      "  \"rouge-2\": {\n",
      "    \"f\": 0.49202009769196187,\n",
      "    \"p\": 0.4464398115165317,\n",
      "    \"r\": 0.6034232722223248\n",
      "  },\n",
      "  \"rouge-l\": {\n",
      "    \"f\": 0.3368956480524842,\n",
      "    \"p\": 0.325564702489678,\n",
      "    \"r\": 0.4660845499376354\n",
      "  }\n",
      "}\n",
      "{\n",
      "  \"rouge-1\": {\n",
      "    \"f\": 0.45293076283983635,\n",
      "    \"p\": 0.40334441072840577,\n",
      "    \"r\": 0.569240653003932\n",
      "  },\n",
      "  \"rouge-2\": {\n",
      "    \"f\": 0.16081417641160342,\n",
      "    \"p\": 0.14383330970975558,\n",
      "    \"r\": 0.20751599922384092\n",
      "  },\n",
      "  \"rouge-l\": {\n",
      "    \"f\": 0.3872429247767316,\n",
      "    \"p\": 0.3760648232400634,\n",
      "    \"r\": 0.5318113753182915\n",
      "  }\n",
      "}\n",
      "\n",
      "117_k3\n",
      "saved ../../to_gpt2/generation_ori_i.txt\n",
      "saved ../../to_gpt2/generation_117_k3_i.txt\n",
      "saved ../../to_gpt2/generation_ori_d.txt\n",
      "saved ../../to_gpt2/generation_117_k3_d.txt\n",
      "BLEU = 27.46, 70.4/51.1/26.8/10.6 (BP=0.864, ratio=0.872, hyp_len=88655, ref_len=101657)\n",
      "It is not advisable to publish scores from multi-bleu.perl.  The scores depend on your tokenizer, which is unlikely to be reproducible from your paper or consistent across research groups.  Instead you should detokenize then use mteval-v14.pl, which has a standard tokenization.  Scores from multi-bleu.perl can still be used for internal purposes when you have a consistent tokenizer.\n",
      "BLEU = 8.65, 52.0/17.9/6.7/2.9 (BP=0.745, ratio=0.773, hyp_len=403590, ref_len=522308)\n",
      "It is not advisable to publish scores from multi-bleu.perl.  The scores depend on your tokenizer, which is unlikely to be reproducible from your paper or consistent across research groups.  Instead you should detokenize then use mteval-v14.pl, which has a standard tokenization.  Scores from multi-bleu.perl can still be used for internal purposes when you have a consistent tokenizer.\n",
      "{\n",
      "  \"rouge-1\": {\n",
      "    \"f\": 0.6049622019038874,\n",
      "    \"p\": 0.5616159146025417,\n",
      "    \"r\": 0.7066381107596577\n",
      "  },\n",
      "  \"rouge-2\": {\n",
      "    \"f\": 0.48209751400467715,\n",
      "    \"p\": 0.454231473589454,\n",
      "    \"r\": 0.5549578370860601\n",
      "  },\n",
      "  \"rouge-l\": {\n",
      "    \"f\": 0.337133035221062,\n",
      "    \"p\": 0.33406057504671044,\n",
      "    \"r\": 0.4270661651494921\n",
      "  }\n",
      "}\n",
      "{\n",
      "  \"rouge-1\": {\n",
      "    \"f\": 0.4321452432369874,\n",
      "    \"p\": 0.40554070356752486,\n",
      "    \"r\": 0.5121492497128495\n",
      "  },\n",
      "  \"rouge-2\": {\n",
      "    \"f\": 0.12973454657568448,\n",
      "    \"p\": 0.1238594403416379,\n",
      "    \"r\": 0.15638370887135006\n",
      "  },\n",
      "  \"rouge-l\": {\n",
      "    \"f\": 0.3707518742704336,\n",
      "    \"p\": 0.3754240957546078,\n",
      "    \"r\": 0.4751393267393666\n",
      "  }\n",
      "}\n",
      "\n",
      "345_k1\n",
      "saved ../../to_gpt2/generation_ori_i.txt\n",
      "saved ../../to_gpt2/generation_345_k1_i.txt\n",
      "saved ../../to_gpt2/generation_ori_d.txt\n",
      "saved ../../to_gpt2/generation_345_k1_d.txt\n",
      "BLEU = 28.52, 63.6/47.9/25.9/10.7 (BP=0.941, ratio=0.943, hyp_len=95851, ref_len=101657)\n",
      "It is not advisable to publish scores from multi-bleu.perl.  The scores depend on your tokenizer, which is unlikely to be reproducible from your paper or consistent across research groups.  Instead you should detokenize then use mteval-v14.pl, which has a standard tokenization.  Scores from multi-bleu.perl can still be used for internal purposes when you have a consistent tokenizer.\n",
      "BLEU = 9.85, 57.1/22.8/10.2/5.1 (BP=0.609, ratio=0.668, hyp_len=349152, ref_len=522308)\n",
      "It is not advisable to publish scores from multi-bleu.perl.  The scores depend on your tokenizer, which is unlikely to be reproducible from your paper or consistent across research groups.  Instead you should detokenize then use mteval-v14.pl, which has a standard tokenization.  Scores from multi-bleu.perl can still be used for internal purposes when you have a consistent tokenizer.\n",
      "{\n",
      "  \"rouge-1\": {\n",
      "    \"f\": 0.6224002583930057,\n",
      "    \"p\": 0.5602594502402446,\n",
      "    \"r\": 0.7637079705321219\n",
      "  },\n",
      "  \"rouge-2\": {\n",
      "    \"f\": 0.5088996138355486,\n",
      "    \"p\": 0.46592924090754156,\n",
      "    \"r\": 0.610739975323844\n",
      "  },\n",
      "  \"rouge-l\": {\n",
      "    \"f\": 0.34460549041101546,\n",
      "    \"p\": 0.33433396745478056,\n",
      "    \"r\": 0.4687353583955177\n",
      "  }\n",
      "}\n",
      "{\n",
      "  \"rouge-1\": {\n",
      "    \"f\": 0.4558712877197142,\n",
      "    \"p\": 0.40216663994756285,\n",
      "    \"r\": 0.5810079196758194\n",
      "  },\n",
      "  \"rouge-2\": {\n",
      "    \"f\": 0.1629681438410416,\n",
      "    \"p\": 0.14380975137786794,\n",
      "    \"r\": 0.21434611391402317\n",
      "  },\n",
      "  \"rouge-l\": {\n",
      "    \"f\": 0.3869450781082354,\n",
      "    \"p\": 0.37397839614288264,\n",
      "    \"r\": 0.5416808057129112\n",
      "  }\n",
      "}\n",
      "\n",
      "time: 6min 49s\n"
     ]
    }
   ],
   "source": [
    "for tag in data.gens:\n",
    "    print(tag)\n",
    "    data.gen = tag\n",
    "    data.to_bleu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tag in data.gens:\n",
    "    print(tag)\n",
    "    data.gen = tag\n",
    "    data.ingr_f1_freq(root=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/4000 [00:00<05:28, 12.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117_k1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 76/4000 [00:06<03:40, 17.80it/s]/data/yueliu/RecipeAnalytics_201906/AA6/utils/evaluation.py:34: UndefinedMetricWarning: input/inputs may be empty\n",
      "  self.warn()\n",
      "100%|██████████| 4000/4000 [04:56<00:00, 13.50it/s]\n",
      "  0%|          | 2/4000 [00:00<04:47, 13.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6241537564179083\n",
      "117_k3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4000/4000 [04:09<00:00, 14.31it/s]\n",
      "  0%|          | 2/4000 [00:00<05:09, 12.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6275425132190814\n",
      "345_k1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4000/4000 [04:36<00:00, 14.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6500015924262921\n",
      "time: 13min 42s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for tag in data.gens:\n",
    "    print(tag)\n",
    "    data.gen = tag\n",
    "    data.ingr_f1_freq(root=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117_k1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4000/4000 [42:02<00:00,  1.47it/s]\n",
      "  0%|          | 0/4000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5186078582567383\n",
      "117_k3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4000/4000 [42:23<00:00,  1.54it/s]\n",
      "  0%|          | 0/4000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5270206439868736\n",
      "345_k1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4000/4000 [39:48<00:00,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5176564111401535\n",
      "time: 2h 4min 13s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for tag in data.gens:\n",
    "    print(tag)\n",
    "    data.gen = tag\n",
    "    data.instr_tree(stem_only = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
